{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7b3854-7adb-432f-8d8a-5066152fc20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete! Saved as t5_formatted_data.json.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "train_data = pd.read_csv(r\"D:\\event_extraction\\data\\train.tsv\",sep = \"\\t\")  \n",
    "def format_data(train_data):\n",
    "    processed_data = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        input_text = row['event_mention']\n",
    "        output_text = row['event'] if row['event'] != \"ND\" else \"No Event\"\n",
    "        processed_data.append({\"input_text\": f\"extract events: {input_text}\", \"output_text\": output_text})\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "processed_data = format_data(train_data)\n",
    "\n",
    "with open(r\"D:\\event_extraction\\data\\train_data.json\", \"w\") as f:\n",
    "    json.dump(processed_data, f, indent=4)\n",
    "\n",
    "print(\"Data preprocessing complete! Saved as t5_formatted_data.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b36ef7-c6c4-4628-8f8b-4811f074db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete! Saved as t5_formatted_data.json.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "test_data = pd.read_csv(r\"D:\\event_extraction\\data\\test.tsv\",sep = \"\\t\")  \n",
    "def format_data(test_data):\n",
    "    processed_data = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        input_text = row['event_mention']\n",
    "        output_text = row['event'] if row['event'] != \"ND\" else \"No Event\"\n",
    "        processed_data.append({\"input_text\": f\"extract events: {input_text}\", \"output_text\": output_text})\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "processed_data = format_data(train_data)\n",
    "\n",
    "with open(r\"D:\\event_extraction\\data\\test_data.json\", \"w\") as f:\n",
    "    json.dump(processed_data, f, indent=4)\n",
    "\n",
    "print(\"Data preprocessing complete! Saved as t5_formatted_data.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814cc2d0-a9ae-47fe-9601-3ce37c6f0110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de24150ea82d489fa226b696ab789347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43447ffae7740d695368f938d93b636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "dataset = load_dataset(\"json\", data_files=r\"D:\\event_extraction\\data\\train_data.json\")\n",
    "testset = load_dataset(\"json\", data_files=r\"D:\\event_extraction\\data\\test_data.json\")\n",
    "\n",
    "# Load T5 tokenizer and model\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c54a6b-bf33-4618-811d-2bdb3a90147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841585734df849809435cd7bc7d23aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91165355a09c402d8fdb6cfcdadd52d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='22890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1001/22890 2:52:41 < 63:03:56, 0.10 it/s, Epoch 0.22/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>0.107638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3148' max='4578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3148/4578 59:36 < 27:05, 0.88 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_data(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"input_text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        example[\"output_text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    # Replace padding token id with -100 to ignore in loss computation\n",
    "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "tokenized_testset = testset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_event_extractor\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_testset[\"train\"],  # Use testset for evaluation\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"./t5_event_extractor\")\n",
    "tokenizer.save_pretrained(\"./t5_event_extractor\")\n",
    "\n",
    "print(\"Fine-tuning complete! Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6a5e73-e2fb-4747-9621-b904935e7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Events: Extraction events: MEK5 signaling regulation il33 modulates endothelial cell migration and focal contact turnover.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def extract_events(sentence):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    input_text = f\"extract events: {sentence}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    # Generate output with beam search\n",
    "    output_ids = model.generate(\n",
    "        inputs.input_ids, \n",
    "        attention_mask=inputs.attention_mask, \n",
    "        max_length=512, \n",
    "        num_beams=3, \n",
    "        no_repeat_ngram_size=2, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "# Example test\n",
    "test_sentence = \"MEK5/ERK5 signaling regulation il33 modulates endothelial cell migration and focal contact turnover.\"\n",
    "print(\"Extracted Events:\", extract_events(test_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3eb18e-8f77-4b0c-99d9-0d32ef8e15b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
